<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />

    

    
    <title>Detecting Lanes using Deep Neural Networks | Nayan Blog</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="keywords" content="Machine Learning,Deep Learning,Lane Detection,Advance Driver Assistance,Autonomous Driving" />
    
    <meta name="description" content="This post explains how to use deep neural networks to detect highway lanes. Lane markings are the main static component on highways.They instruct the vehicles to interactively and safely drive on the">
<meta name="keywords" content="Machine Learning,Deep Learning,Lane Detection,Advance Driver Assistance,Autonomous Driving">
<meta property="og:type" content="article">
<meta property="og:title" content="Detecting Lanes using Deep Neural Networks">
<meta property="og:url" content="https:&#x2F;&#x2F;nayan.co&#x2F;blog&#x2F;2019&#x2F;11&#x2F;26&#x2F;Detecting-Lanes-using-Deep-Neural-Networks&#x2F;index.html">
<meta property="og:site_name" content="Nayan Blog">
<meta property="og:description" content="This post explains how to use deep neural networks to detect highway lanes. Lane markings are the main static component on highways.They instruct the vehicles to interactively and safely drive on the">
<meta property="og:locale" content="en">
<meta property="og:image" content="https:&#x2F;&#x2F;nayan.co&#x2F;blog&#x2F;2019&#x2F;11&#x2F;26&#x2F;Detecting-Lanes-using-Deep-Neural-Networks&#x2F;dir_structure.png">
<meta property="og:updated_time" content="2019-11-26T10:43:00.836Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;nayan.co&#x2F;blog&#x2F;2019&#x2F;11&#x2F;26&#x2F;Detecting-Lanes-using-Deep-Neural-Networks&#x2F;dir_structure.png">
    

    

    
        <link rel="icon" href="/blog/css/images/favicon.png" />
    

    <link rel="stylesheet" href="/blog/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/blog/libs/titillium-web/styles.css">
    <link rel="stylesheet" href="/blog/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/blog/css/style.css">

    <script src="/blog/libs/jquery/3.4.1/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/blog/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/blog/libs/justified-gallery/justifiedGallery.min.css">
    
    
    


<link rel="alternate" href="/blog/atom.xml" title="Nayan Blog" type="application/atom+xml">
</head>

<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/blog/" class="logo"></a>
                    </h1>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/blog/">Home</a>
                                </li>
                            
                                        <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/blog/categories/AI/">AI</a></li></ul>
                                    
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/blog/archives/index.html">Archive</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/blog/',
        CONTENT_URL: '/blog/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/blog/js/insight.js"></script>

</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>
        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/blog/categories/AI/">AI</a>
    </h1>
</div>

                        <div class="main-body-content">
                            <article id="post-Detecting-Lanes-using-Deep-Neural-Networks" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        Detecting Lanes using Deep Neural Networks
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
    <div class="article-date">
      <i class="fa fa-calendar"></i>
      <a href="/blog/2019/11/26/Detecting-Lanes-using-Deep-Neural-Networks/" class="article-date">
         <time datetime="2019-11-26T11:17:10.000Z" itemprop="datePublished">2019-11-26</time>
      </a>
    </div>


                
  <div class="article-author">
    Anand Kummari
  </div>


                
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/blog/tags/Advance-Driver-Assistance/" rel="tag">Advance Driver Assistance</a>, <a class="tag-link" href="/blog/tags/Autonomous-Driving/" rel="tag">Autonomous Driving</a>, <a class="tag-link" href="/blog/tags/Deep-Learning/" rel="tag">Deep Learning</a>, <a class="tag-link" href="/blog/tags/Lane-Detection/" rel="tag">Lane Detection</a>, <a class="tag-link" href="/blog/tags/Machine-Learning/" rel="tag">Machine Learning</a>
    </div>

                

                

            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <blockquote>
<p>This post explains how to use deep neural networks to detect highway lanes. Lane markings are the main static component on highways.<strong>They instruct the vehicles to interactively and safely drive on the highways.</strong> Lane detection is also an important task in autonomous driving, which provides localization information to the control of the car. It is also used in <strong>ADAS(Advanced Driver Assistance System)</strong>.</p>
</blockquote>
<p>For the task of lane detection, we have two open-source datasets available. One is the Tusimple dataset and the other is the CULane dataset. Let’s have a brief look at one of the datasets.</p>
<h2 id="Tusimple-Dataset"><a href="#Tusimple-Dataset" class="headerlink" title="Tusimple Dataset"></a>Tusimple Dataset</h2><p>This dataset was released as part of the Tusimple Lane Detection Challenge. It contains 3626 video clips of 1 sec duration each. Each of these video clips contains 20 frames of which, the last frame is annotated. These videos were captured by mounting the cameras on a vehicle dashboard. You can download the dataset from <a href="https://github.com/TuSimple/tusimple-benchmark/issues/3" target="_blank" rel="noopener">here</a>.</p>
<p>The directory structure looks like the figure below,</p>
<img src="/blog/2019/11/26/Detecting-Lanes-using-Deep-Neural-Networks/dir_structure.png" class="" title="Dataset directory structure">

<p>Each sub-directory contains 20 sequential images of which, the last frame is annotated. label_data_(date).json contains labels in JSON format for the last frame. Each line in the JSON file is a dictionary with key values…</p>
<p><strong>raw_file</strong>: string type. the file path in the clip</p>
<p><strong>lanes</strong>: it is a list of list of lanes. Each list corresponds to a lane and each element of the inner list is x-coordinate of ground truth lane.</p>
<p><strong>h_samples</strong>: it is a list of height values corresponding to the lanes. Each element in this list is y-coordinate of ground truth lane</p>
<p>In this dataset, at most four lanes are annotated - the two ego lanes (two lane boundaries in which the vehicle is currently located) and the lanes to the right and left of ego lanes. All the lanes are annotated at an equal interval of height, therefore h_samples contain only one list whose elements correspond to y-coordinates for all lists in lanes. For a point in h_samples, if there is no lane at the location, its corresponding x-coordinate has -2. For example, a line in the JSON file looks like :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;lanes&quot;: [</span><br><span class="line">        [-2, -2, -2, -2, 632, 625, 617, 609, 601, 594, 586, 578, 570, 563, 555, 547, 539, 532, 524, 516, 508, 501, 493, 485, 477, 469, 462, 454, 446, 438, 431, 423, 415, 407, 400, 392, 384, 376, 369, 361, 353, 345, 338, 330, 322, 314, 307, 299],</span><br><span class="line">        [-2, -2, -2, -2, 719, 734, 748, 762, 777, 791, 805, 820, 834, 848, 863, 877, 891, 906, 920, 934, 949, 963, 978, 992, 1006, 1021, 1035, 1049, 1064, 1078, 1092, 1107, 1121, 1135, 1150, 1164, 1178, 1193, 1207, 1221, 1236, 1250, 1265, -2, -2, -2, -2, -2],</span><br><span class="line">        [-2, -2, -2, -2, -2, 532, 503, 474, 445, 416, 387, 358, 329, 300, 271, 241, 212, 183, 154, 125, 96, 67, 38, 9, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2],</span><br><span class="line">        [-2, -2, -2, 781, 822, 862, 903, 944, 984, 1025, 1066, 1107, 1147, 1188, 1229, 1269, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]</span><br><span class="line">       ],</span><br><span class="line">  &quot;h_samples&quot;: [240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 500, 510, 520, 530, 540, 550, 560, 570, 580, 590, 600, 610, 620, 630, 640, 650, 660, 670, 680, 690, 700, 710],</span><br><span class="line">  &quot;raw_file&quot;: &quot;path_to_clip&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>It says that there are four lanes in the image, and the first lane starts at (632,280), the second lane starts at (719,280), the third lane starts at (532,290) and the fourth lane starts at (781,270).</p>
<h2 id="DataSet-Visualization"><a href="#DataSet-Visualization" class="headerlink" title="DataSet Visualization"></a>DataSet Visualization</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># import required packages</span><br><span class="line">import json</span><br><span class="line">import numpy as np</span><br><span class="line">import cv2</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"># read each line of json file</span><br><span class="line">json_gt = [json.loads(line) for line in open(&apos;label_data.json&apos;)]</span><br><span class="line">gt = json_gt[0]</span><br><span class="line">gt_lanes = gt[&apos;lanes&apos;]</span><br><span class="line">y_samples = gt[&apos;h_samples&apos;]</span><br><span class="line">raw_file = gt[&apos;raw_file&apos;]</span><br><span class="line"># see the image</span><br><span class="line">img = cv2.imread(raw_file)</span><br><span class="line">cv2.imshow(&apos;image&apos;,img)</span><br><span class="line">cv2.WaitKey(0)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

<img src="/blog/2019/11/26/Detecting-Lanes-using-Deep-Neural-Networks/image_1.jpg" class="" title="Image 1. Raw image from the dataset">

<p>Now see the JSON points visualization on the image</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">gt_lanes_vis = [[(x, y) for (x, y) in zip(lane, y_samples)</span><br><span class="line">                  if x &gt;= 0] for lane in gt_lanes]</span><br><span class="line">img_vis = img.copy()</span><br><span class="line"></span><br><span class="line">for lane in gt_lanes_vis:</span><br><span class="line">    cv2.polylines(img_vis, np.int32([lane]), isClosed=False,</span><br><span class="line">                   color=(0,255,0), thickness=5)</span><br></pre></td></tr></table></figure>

<img src="/blog/2019/11/26/Detecting-Lanes-using-Deep-Neural-Networks/image_2.jpg" class="" title="Image 2. Label visualications of image">

<p>Now, we have understood the dataset, but we can not pass the above image as a label for the neural network since <strong>grayscale images with values ranging from zero to num_classes -1 are to be passed to the deep convolution neural network to outputs an image containing predicted lanes</strong>. So, we need to generate label images for the JSON files. Label images can be generated using <strong>OpenCV</strong> by drawing lines passing through the points in the JSON file.</p>
<p>OpenCV has an inbuilt function to draw multiple lines through a set of points. OpenCV’s Polylines method can be used here. First, create a mask of all zeros with height and width equal to the raw file’s height and width using numpy. <strong>The image size can be reduced to maintain lesser computations during training, but do not forget to maintain the same aspect ratio</strong>.</p>
<h2 id="Generating-Labels"><a href="#Generating-Labels" class="headerlink" title="Generating Labels"></a>Generating Labels</h2><p>The label should be a grayscale image. Generate one label for each clip from the JSON file. First, create a mask of black pixels with a shape similar to the raw_file image from the JSON file. Now, using OpenCV’s polylines method draw lines with different colors (each corresponding to each lane in lanes) on the mask image using the lanes and h_samples from the JSON file. From the three channeled mask image generate a gray scale mask image with values as class numbers. Likewise, create labels for all the images in the JSON file. You can resize the image and its label to a smaller size for lesser computations.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mask = np.zeros_like(img)</span><br><span class="line">colors = [[255,0,0],[0,255,0],[0,0,255],[0,255,255]]</span><br><span class="line">for i in range(len(gt_lanes_vis)):</span><br><span class="line">    cv2.polylines(mask, np.int32([gt_lanes_vis[i]]), isClosed=False,color=colors[i], thickness=5)</span><br><span class="line">!! create grey-scale label image</span><br><span class="line">label = np.zeros((720,1280),dtype = np.uint8)</span><br><span class="line">for i in range(len(colors)):</span><br><span class="line">   label[np.where((mask == colors[i]).all(axis = 2))] = i+1</span><br></pre></td></tr></table></figure>
<img src="/blog/2019/11/26/Detecting-Lanes-using-Deep-Neural-Networks/image_3.jpg" class="" title="Image 3. Generated mask image">

<h2 id="Build-and-Train-Model"><a href="#Build-and-Train-Model" class="headerlink" title="Build and Train Model"></a>Build and Train Model</h2><p>Lane Detection is essentially an image segmentation problem. So I am using the <strong>ERFNET model</strong> for this task, which is efficient and fast. Originally ERFNET was proposed for semantic segmentation problems, but it can also be extended to other image segmentation problems. You can check out for its paper <a href="https://ieeexplore.ieee.org/abstract/document/8063438" target="_blank" rel="noopener">here</a>. It is a CNN with Encoder, Decoder and dilated convolutions along with non-bottleneck residual layers. See Fig.1 for model architecture.</p>
<img src="/blog/2019/11/26/Detecting-Lanes-using-Deep-Neural-Networks/figure_1.png" class="" title="Figure 1. Model Architecture">

<p>Build and create an object of the model. Train it over the dataset created above, for a sufficient number of epochs with Binary Cross Entropy loss or custom loss function which minimizes the per-pixel error. For better memory usage, create a dataset generator and train the model over it. Generators remove the burden of loading all the images into memory (if your dataset is of large size, you should use a generator) which leads to eating up of all memory and the other processes can’t work properly. Fig 2 shows the layers of ERFNET with input and output dimensions.</p>
<img src="/blog/2019/11/26/Detecting-Lanes-using-Deep-Neural-Networks/figure_2.png" class="" title="Figure 2. Model layers with input and output shapes">

<h2 id="Evaluate-Model"><a href="#Evaluate-Model" class="headerlink" title="Evaluate Model"></a>Evaluate Model</h2><p>After training, get the model’s predictions using the code snippet below. I have implemented this in Pytorch. I use the color_lanes method to convert output images from the model (which are two channeled with values as class numbers) to three channeled images. im_seg is the final overlayed image shown in Image 4.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">#using pytorch</span><br><span class="line">import torch</span><br><span class="line">from torchvision.transforms import ToTensor</span><br><span class="line">def color_lanes(image, classes, i, color, HEIGHT, WIDTH):</span><br><span class="line">    buffer_c1 = np.zeros((HEIGHT, WIDTH), dtype=np.uint8)</span><br><span class="line">    buffer_c1[classes == i] = color[0]</span><br><span class="line">    image[:, :, 0] += buffer_c1</span><br><span class="line">    buffer_c2 = np.zeros((HEIGHT, WIDTH), dtype=np.uint8)</span><br><span class="line">    buffer_c2[classes == i] = color[1]</span><br><span class="line">    image[:, :, 1] += buffer_c2</span><br><span class="line">    buffer_c3 = np.zeros((HEIGHT, WIDTH), dtype=np.uint8)</span><br><span class="line">    buffer_c3[classes == i] = color[2]</span><br><span class="line">    image[:, :, 2] += buffer_c3</span><br><span class="line">    return image</span><br><span class="line">img = cv2.imread(&apos;images/test.jpg&apos;) </span><br><span class="line">img = cv2.resize(img,(WIDTH, HEIGHT),interpolation = cv2.INETR_CUBIC)</span><br><span class="line">op_transforms = transforms.Compose([transforms.ToTensor()])</span><br><span class="line">device = torch.device(&apos;cuda&apos; if torch.cuda.is_available() else &apos;cpu&apos;)</span><br><span class="line">im_tensor = torch.unsqueeze(op_transforms(img), dim=0)</span><br><span class="line">im_tensor = im_tensor.to(device)</span><br><span class="line">model = ERFNET(5)</span><br><span class="line">model = model.to(device)</span><br><span class="line">model = model.eval()</span><br><span class="line">out = model(im_tensor)</span><br><span class="line">out = out.max(dim=1)[1]</span><br><span class="line">out_np = out.cpu().numpy()[0]</span><br><span class="line">out_viz = np.zeros((HEIGHT, WIDTH, 3))</span><br><span class="line">for i in range(1, NUM_LD_CLASSES):</span><br><span class="line">    rand_c1 = random.randint(1, 255)</span><br><span class="line">    rand_c2 = random.randint(1, 255)</span><br><span class="line">    rand_c3 = random.randint(1, 255)</span><br><span class="line">    out_viz = color_lanes(</span><br><span class="line">            out_viz, out_np,</span><br><span class="line">            i, (rand_c1, rand_c2, rand_c3), HEIGHT, WIDTH)</span><br><span class="line">instance_im = out_viz.astype(np.uint8)</span><br><span class="line">im_seg = cv2.addWeighted(img, 1, instance_im, 1, 0)</span><br></pre></td></tr></table></figure>

<img src="/blog/2019/11/26/Detecting-Lanes-using-Deep-Neural-Networks/image_4.jpg" class="" title="Image 4. Final predicted image">

<p>Thanks for reading it…</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol>
<li>ERFNet: Efficient Residual Factorized ConvNet for Real-time Semantic 2. Segmentation.</li>
<li>Lane Detection and Classification using CNNs.</li>
<li><a href="https://www.mdpi.com/sensors/sensors-19-00503/article_deploy/html/images/sensors-19-00503-g004.png" target="_blank" rel="noopener">https://www.mdpi.com/sensors/sensors-19-00503/article_deploy/html/images/sensors-19-00503-g004.png</a></li>
</ol>

        </div>
        <footer class="article-footer">
            



    <a data-url="https://nayan.co/blog/2019/11/26/Detecting-Lanes-using-Deep-Neural-Networks/" data-id="ck3fqfae50001vsn98pwf5jgp" class="article-share-link"><i class="fa fa-share"></i>Share</a>
<script>
    (function ($) {
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

        </footer>
    </div>
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "author": {
            "@type": "Person",
            "name": "NayanTech"
        },
        "headline": "Detecting Lanes using Deep Neural Networks",
        "image": "https://nayan.co/blog/blog/2019/11/26/Detecting-Lanes-using-Deep-Neural-Networks/dir_structure.png",
        "keywords": "Machine Learning Deep Learning Lane Detection Advance Driver Assistance Autonomous Driving",
        "genre": "AI",
        "datePublished": "2019-11-26",
        "dateCreated": "2019-11-26",
        "dateModified": "2019-11-26",
        "url": "https://nayan.co/blog//2019/11/26/Detecting-Lanes-using-Deep-Neural-Networks/",
        "description": "
This post explains how to use deep neural networks to detect highway lanes. Lane markings are the main static component on highways.They instruct the vehicles to interactively and safely drive on the",
        "wordCount": 1750
    }
</script>

</article>

    <section id="comments">
    
    </section>



                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>follow:</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="youtube" href="https://www.youtube.com/channel/UCgglHs52FLwmQNyxND57c2Q" target="_blank" rel="noopener">
                        <i class="icon fa fa-youtube"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="twitter" href="https://twitter.com/nayancam" target="_blank" rel="noopener">
                        <i class="icon fa fa-twitter"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="facebook" href="https://www.facebook.com/NAYANCAM/" target="_blank" rel="noopener">
                        <i class="icon fa fa-facebook"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="instagram" href="https://www.instagram.com/nayantechno/" target="_blank" rel="noopener">
                        <i class="icon fa fa-instagram"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="linkedin" href="https://in.linkedin.com/company/nayancam" target="_blank" rel="noopener">
                        <i class="icon fa fa-linkedin"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/blog/2019/11/26/Text-detection-in-number-plates/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">newer</strong>
        <p class="article-nav-title">
        
            Text detection in number plates
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
</nav>

    
    <div class="widgets-container">
        
            
                

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">recents</h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/blog/2019/11/26/Text-detection-in-number-plates/" class="thumbnail">
    
    
        <span style="background-image:url(/blog/2019/11/26/Text-detection-in-number-plates/Figure_1.png)" alt="Text detection in number plates" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"></p>
                            <p class="item-title"><a href="/blog/2019/11/26/Text-detection-in-number-plates/" class="title">Text detection in number plates</a></p>
                            <p class="item-date"><time datetime="2019-11-26T15:21:29.000Z" itemprop="datePublished">2019-11-26</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/blog/2019/11/26/Detecting-Lanes-using-Deep-Neural-Networks/" class="thumbnail">
    
    
        <span style="background-image:url(/blog/2019/11/26/Detecting-Lanes-using-Deep-Neural-Networks/dir_structure.png)" alt="Detecting Lanes using Deep Neural Networks" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/blog/categories/AI/">AI</a></p>
                            <p class="item-title"><a href="/blog/2019/11/26/Detecting-Lanes-using-Deep-Neural-Networks/" class="title">Detecting Lanes using Deep Neural Networks</a></p>
                            <p class="item-date"><time datetime="2019-11-26T11:17:10.000Z" itemprop="datePublished">2019-11-26</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">categories</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/blog/categories/AI/">AI</a><span class="category-list-count">1</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">archives</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2019/11/">November 2019</a><span class="archive-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">tags</h3>
        <div class="widget">
            <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/Advance-Driver-Assistance/" rel="tag">Advance Driver Assistance</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/Autonomous-Driving/" rel="tag">Autonomous Driving</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/Deep-Learning/" rel="tag">Deep Learning</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/Lane-Detection/" rel="tag">Lane Detection</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/Machine-Learning/" rel="tag">Machine Learning</a><span class="tag-list-count">1</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">tag cloud</h3>
        <div class="widget tagcloud">
            <a href="/blog/tags/Advance-Driver-Assistance/" style="font-size: 10px;">Advance Driver Assistance</a> <a href="/blog/tags/Autonomous-Driving/" style="font-size: 10px;">Autonomous Driving</a> <a href="/blog/tags/Deep-Learning/" style="font-size: 10px;">Deep Learning</a> <a href="/blog/tags/Lane-Detection/" style="font-size: 10px;">Lane Detection</a> <a href="/blog/tags/Machine-Learning/" style="font-size: 10px;">Machine Learning</a>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">links</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="https://nayan.co">Nayan</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
        
    </div>
</aside>

                </div>
            </div>
        </div>
        <section class="footer">
  <div class="container">
    <div class="container-inner">
        <div class="flexContainer">
      <div class="col-lg-3">

        <h3>NAYAN (Partner's offices)</h3>
        <p>Gulf Business Machines (UCMC LLC.) <br>
          Emarat Atrium Building, Wing B, 3rd Floor<br>
          Opposite Holiday Inn (Al Safa)<br>
          Sheikh Zayed Road, PO Box 9226, Dubai, UAE
        </p>


      </div>
      <div class="col-lg-6">
        <div class="footer-links">
          <img src="css/images/nayan-logo.png" alt="">
          <p><span>Our Goal: </span> Stewarding and Monitoring all roadways, on demand<p>

          <ul>
          <li><a href="https://www.facebook.com/NAYANCAM/" target="_blank"><i class="fa fa-facebook"></i></a></li>
          <li><a href="https://twitter.com/nayancam" target="_blank"><i class="fa fa-twitter"></i></a></li>
          <li><a href="https://www.youtube.com/channel/UCgglHs52FLwmQNyxND57c2Q" target="_blank"><i class="fa fa-youtube-play"></i></a></li>
          <li><a href="https://www.instagram.com/nayantechno/" target="_blank"><i class="fa fa-instagram"></i></a></li>
          </ul>
        </div>
      </div>
      <div class="col-lg-3">
        <ul class="footer-menu">
          <li><a href="/">Home</a></li>
          <li><a href="/blog/archives/index.html">Archive</a></li>
          <li><a href="https://nayan.co" target="_blank">Nayan</a></li>
        </ul>

      </div>
    </div>
    </div>
  </div>

</section>
<section class="credits">
  <div class="container">
    <div class="row">
      <div class="col-lg-12">

        <p>&copy; 2019 NAYAN <span> All Rights Reserved</span></p>
      </div>
    </div>
  </div>
</section>

        


    
        <script src="/blog/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/blog/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/blog/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/blog/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/blog/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/blog/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/blog/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/blog/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/blog/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/blog/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    

    



<!-- Custom Scripts -->
<script src="/blog/js/main.js"></script>

    </div>
</body>
</html>
